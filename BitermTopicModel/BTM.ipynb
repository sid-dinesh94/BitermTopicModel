{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import operator\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "code_folding": [
     25,
     31,
     84,
     96,
     170
    ],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class BTM(object):\n",
    "    def __init__(self, data_path, alpha, beta, num_iter, num_topic, output_dir):\n",
    "        self.data_path = data_path\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.num_iter = num_iter\n",
    "        self.num_topic = num_topic\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        self.word2Id = {}\n",
    "        self.Id2Word = {}\n",
    "        self.vocab_size = 0\n",
    "        \n",
    "        self.wordId_corpus = []\n",
    "        \n",
    "        self.biterms_in_doc = [] #list of dictionaries long->int\n",
    "        self.num_doc_biterm = defaultdict(int)\n",
    "        self.biterms = [] #List of numbers\n",
    "\n",
    "        self.topic_biterm = []\n",
    "        self.topic_word_num = [] #list of lists\n",
    "        self.num_topic_biterm = []\n",
    "        \n",
    "        self.biterm_sum = {} #Map from long to double\n",
    "        \n",
    "    def get_file_reader(self, path = None):\n",
    "        if path is None:\n",
    "            path = self.data_path\n",
    "        f = open(path, 'r')\n",
    "        return f\n",
    "    \n",
    "    def get_file_writer(self,path, append = False):\n",
    "        if append:\n",
    "            read_mode = 'a'\n",
    "        else:\n",
    "            read_mode = 'w'\n",
    "        g = open(os.path.join(self.output_dir, path), read_mode)\n",
    "        return g\n",
    "    \n",
    "    def print_params(self):\n",
    "        params = ['alpha','beta','num_iter','num_topic','topic_word_num','num_topic_biterm','topic_biterm']\n",
    "        for param in params:\n",
    "            print(param,':',getattr(self, param))\n",
    "            print('-'*40)\n",
    "    \n",
    "    def load_data(self):\n",
    "        f = self.get_file_reader()\n",
    "        for line in f.readlines():\n",
    "            words = line.split()\n",
    "            curr_doc = []\n",
    "            for word in words:\n",
    "                if word not in self.word2Id:\n",
    "                    index = len(self.word2Id)\n",
    "                    self.word2Id[word] = index\n",
    "                    self.Id2Word[index] = word\n",
    "                curr_doc.append(self.word2Id[word])\n",
    "            self.wordId_corpus.append(curr_doc)\n",
    "        f.close()\n",
    "        \n",
    "        self.num_doc_biterm = [0]*len(self.wordId_corpus)\n",
    "    \n",
    "    def init_model(self):\n",
    "        for doc_number, doc in enumerate(self.wordId_corpus):\n",
    "            oneCop = defaultdict(int)\n",
    "            for word1 in doc:\n",
    "                for word2 in doc:\n",
    "                    if(word1<word2):\n",
    "                        item_num = word1*1000000+word2 #encoding the biterms\n",
    "                        oneCop[item_num] +=1\n",
    "                        self.biterms.append(item_num)\n",
    "                        self.num_doc_biterm[doc_number] +=1\n",
    "            self.biterms_in_doc.append(oneCop)\n",
    "            \n",
    "        self.vocab_size = len(self.word2Id)\n",
    "        \n",
    "        self.topic_biterm = [0]*len(self.biterms)\n",
    "        self.topic_word_num = {j: {i:0 for i in range(self.num_topic)} for j in range(self.vocab_size)}\n",
    "        print(len(self.topic_word_num), len(self.topic_word_num[0]))\n",
    "        self.num_topic_biterm = [1]*self.num_topic\n",
    "        \n",
    "        for biterm_index, biterm in enumerate(self.biterms):\n",
    "            topic_id = random.randint(0, self.num_topic-1)\n",
    "            #if biterm_index  5:\n",
    "                #print(biterm, biterm%1000000, biterm//1000000)\n",
    "                #print(self.topic_word_num)\n",
    "            self.topic_word_num[biterm%1000000][topic_id] +=1\n",
    "            self.topic_word_num[biterm//1000000][topic_id] +=1\n",
    "            self.topic_biterm[biterm_index] = topic_id\n",
    "            \n",
    "    def save_topic_words(self, topic_word_num = 10):\n",
    "        writer = self.get_file_writer(path = 'model-final-topic-words.txt')\n",
    "        for topic_id in range(self.num_topic):\n",
    "            topic_line = {}\n",
    "            for word_id, word in enumerate(self.word2Id):\n",
    "                topic_line[word_id] = self.topic_word_num[word_id][topic_id]/ self.num_topic_biterm[topic_id] / 2\n",
    "            sorted_topic_line = sorted(topic_line.items(), key = operator.itemgetter(1) )\n",
    "            writer.write(\"Topic:\"+str(topic_id) + '\\n')\n",
    "            for topic_word,score in sorted_topic_line[:topic_word_num]:\n",
    "                writer.write(\"\\t\"+str(self.Id2Word[topic_word])+\"\\t\"+str(score) + '\\n')\n",
    "        writer.close()\n",
    "    \n",
    "    def save_wordIds(self):\n",
    "        writer = self.get_file_writer(path = 'model-final-wordIds.txt')\n",
    "        for key,value in self.word2Id.items():\n",
    "            writer.write(str(key) + ' ' + str(value) + '\\n')\n",
    "        writer.close()\n",
    "        \n",
    "    def get_sum(self, biterm):\n",
    "        if biterm not in self.biterm_sum:\n",
    "            word1 = biterm//1000000\n",
    "            word2 = biterm%1000000\n",
    "            sum = 0\n",
    "            for topic_id in range(self.num_topic):\n",
    "                calculation = (self.num_topic_biterm[topic_id] + self.alpha) * (self.topic_word_num[word1][topic_id] + self.beta) * (self.topic_word_num[word2][topic_id] + self.beta) / ((2 * self.num_topic_biterm[topic_id] ) + (self.vocab_size * self.beta))**2\n",
    "                sum += calculation\n",
    "            self.biterm_sum[biterm] = sum\n",
    "        return self.biterm_sum[biterm]\n",
    "        \n",
    "    def save_theta(self):\n",
    "        writer = self.get_file_writer(path = 'model-final-theta.txt')\n",
    "\n",
    "        for doc_index, line in enumerate(self.biterms_in_doc):\n",
    "            for topic_id in range(self.num_topic):\n",
    "                one_sum = 0\n",
    "                for key in line:\n",
    "                    word1 = key//1000000\n",
    "                    word2 = key%1000000\n",
    "                    one_sum += ((line[key]/self.num_doc_biterm[doc_index]) * ((self.num_topic_biterm[topic_id] + self.alpha) * (self.topic_word_num[word1][topic_id] + self.beta) * (self.topic_word_num[word2][topic_id] + self.beta) / ((2 * self.num_topic_biterm[topic_id] ) + (self.vocab_size * self.beta))**2)/(self.get_sum(key)))\n",
    "                writer.write(str(one_sum) + \" \")\n",
    "            writer.write('\\n')\n",
    "        writer.close()\n",
    "        \n",
    "    def save_phi(self):\n",
    "        writer = self.get_file_writer(path = 'model-final-phi.txt')\n",
    "        for topic_id in range(self.num_topic):\n",
    "            for word_id in self.Id2Word:\n",
    "                calculation = (self.topic_word_num[word_id][topic_id] + self.beta) / ((self.num_topic_biterm[topic_id] * 2) + (self.vocab_size * self.beta))\n",
    "                writer.write(str(calculation) + ' ')\n",
    "            writer.write('\\n')\n",
    "        writer.close()\n",
    "        \n",
    "    \n",
    "    def build_model(self):\n",
    "        for it in range(self.num_iter):\n",
    "            start_time = time.time()\n",
    "            for biterm_index, old_topic_id in enumerate(self.topic_biterm):\n",
    "                word1 = self.biterms[biterm_index]//1000000\n",
    "                word2 = self.biterms[biterm_index]%1000000\n",
    "                self.topic_word_num[word1][old_topic_id] -=1\n",
    "                self.topic_word_num[word2][old_topic_id] -=1\n",
    "                self.num_topic_biterm[old_topic_id] -=1\n",
    "                \n",
    "                new_topic_id = -1\n",
    "                \n",
    "                p = [0]*self.num_topic\n",
    "                for k in range(self.num_topic):\n",
    "                    p[k] = (self.num_topic_biterm[k] + self.alpha) * (self.topic_word_num[word1][k] + self.beta) * (self.topic_word_num[word2][k] + self.beta) / ((2 * self.num_topic_biterm[k] ) + (self.vocab_size * self.beta))**2\n",
    "                    \n",
    "                for k in range(1,self.num_topic):\n",
    "                    p[k] += p[k-1]\n",
    "                \n",
    "                u = random.random() * p[-1]\n",
    "                for k in range(self.num_topic):\n",
    "                    if u < p[k]:\n",
    "                        new_topic_id = k\n",
    "                        break\n",
    "                \n",
    "                self.topic_word_num[word1][new_topic_id] +=1\n",
    "                self.topic_word_num[word2][new_topic_id] +=1\n",
    "                self.num_topic_biterm[new_topic_id] += 1\n",
    "                \n",
    "                self.topic_biterm[biterm_index] = new_topic_id\n",
    "                \n",
    "            print('Finished iteration:', it, 'Time taken:' + str(time.time()-start_time))\n",
    "    \n",
    "    def save_result(self):\n",
    "        self.save_topic_words(20)\n",
    "        self.save_theta()\n",
    "        self.save_wordIds()\n",
    "        self.save_phi()\n",
    "        \n",
    "    def run(self):\n",
    "        self.load_data()\n",
    "        self.init_model()\n",
    "        self.build_model()\n",
    "        self.save_result()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "btm = BTM(data_path='../Data/sample-data.txt',alpha=2,beta=0.001, num_iter=100, num_topic=50, output_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "957 50\n",
      "Finished iteration: 0 Time taken:1.0762667655944824\n",
      "Finished iteration: 1 Time taken:1.1107900142669678\n",
      "Finished iteration: 2 Time taken:1.1293015480041504\n",
      "Finished iteration: 3 Time taken:1.067258596420288\n",
      "Finished iteration: 4 Time taken:1.1122910976409912\n",
      "Finished iteration: 5 Time taken:1.231374740600586\n",
      "Finished iteration: 6 Time taken:1.4300165176391602\n",
      "Finished iteration: 7 Time taken:1.4034972190856934\n",
      "Finished iteration: 8 Time taken:1.1728334426879883\n",
      "Finished iteration: 9 Time taken:1.1518194675445557\n",
      "Finished iteration: 10 Time taken:1.1262991428375244\n",
      "Finished iteration: 11 Time taken:1.0747637748718262\n",
      "Finished iteration: 12 Time taken:1.0622549057006836\n",
      "Finished iteration: 13 Time taken:1.0277326107025146\n",
      "Finished iteration: 14 Time taken:1.0302302837371826\n",
      "Finished iteration: 15 Time taken:1.0277307033538818\n",
      "Finished iteration: 16 Time taken:1.0382375717163086\n",
      "Finished iteration: 17 Time taken:1.1117892265319824\n",
      "Finished iteration: 18 Time taken:1.124800205230713\n",
      "Finished iteration: 19 Time taken:1.1643273830413818\n",
      "Finished iteration: 20 Time taken:1.112816333770752\n",
      "Finished iteration: 21 Time taken:1.050746202468872\n",
      "Finished iteration: 22 Time taken:1.0617542266845703\n",
      "Finished iteration: 23 Time taken:1.0532493591308594\n",
      "Finished iteration: 24 Time taken:1.0427403450012207\n",
      "Finished iteration: 25 Time taken:1.058251142501831\n",
      "Finished iteration: 26 Time taken:1.0832695960998535\n",
      "Finished iteration: 27 Time taken:1.0312328338623047\n",
      "Finished iteration: 28 Time taken:1.1187958717346191\n",
      "Finished iteration: 29 Time taken:1.119295597076416\n",
      "Finished iteration: 30 Time taken:1.0597529411315918\n",
      "Finished iteration: 31 Time taken:1.0547490119934082\n",
      "Finished iteration: 32 Time taken:1.0232274532318115\n",
      "Finished iteration: 33 Time taken:1.114293098449707\n",
      "Finished iteration: 34 Time taken:1.0102167129516602\n",
      "Finished iteration: 35 Time taken:1.1012823581695557\n",
      "Finished iteration: 36 Time taken:1.029733419418335\n",
      "Finished iteration: 37 Time taken:1.0942769050598145\n",
      "Finished iteration: 38 Time taken:1.1633269786834717\n",
      "Finished iteration: 39 Time taken:1.0572707653045654\n",
      "Finished iteration: 40 Time taken:1.0672593116760254\n",
      "Finished iteration: 41 Time taken:1.061753749847412\n",
      "Finished iteration: 42 Time taken:1.0977811813354492\n",
      "Finished iteration: 43 Time taken:1.085270881652832\n",
      "Finished iteration: 44 Time taken:1.0612545013427734\n",
      "Finished iteration: 45 Time taken:1.0687589645385742\n",
      "Finished iteration: 46 Time taken:1.0767743587493896\n",
      "Finished iteration: 47 Time taken:1.181340217590332\n",
      "Finished iteration: 48 Time taken:1.13730788230896\n",
      "Finished iteration: 49 Time taken:1.0722620487213135\n",
      "Finished iteration: 50 Time taken:1.0237290859222412\n",
      "Finished iteration: 51 Time taken:1.0827677249908447\n",
      "Finished iteration: 52 Time taken:1.019730567932129\n",
      "Finished iteration: 53 Time taken:1.0947766304016113\n",
      "Finished iteration: 54 Time taken:1.1850512027740479\n",
      "Finished iteration: 55 Time taken:2.2455427646636963\n",
      "Finished iteration: 56 Time taken:1.148317813873291\n",
      "Finished iteration: 57 Time taken:1.0637538433074951\n",
      "Finished iteration: 58 Time taken:1.0283777713775635\n",
      "Finished iteration: 59 Time taken:1.03623628616333\n",
      "Finished iteration: 60 Time taken:1.1147935390472412\n",
      "Finished iteration: 61 Time taken:1.069258451461792\n",
      "Finished iteration: 62 Time taken:1.0212254524230957\n",
      "Finished iteration: 63 Time taken:1.0427422523498535\n",
      "Finished iteration: 64 Time taken:1.0751128196716309\n",
      "Finished iteration: 65 Time taken:1.1247994899749756\n",
      "Finished iteration: 66 Time taken:1.0297646522521973\n",
      "Finished iteration: 67 Time taken:1.0842914581298828\n",
      "Finished iteration: 68 Time taken:1.0632553100585938\n",
      "Finished iteration: 69 Time taken:1.0617549419403076\n",
      "Finished iteration: 70 Time taken:1.102283239364624\n",
      "Finished iteration: 71 Time taken:1.1268000602722168\n",
      "Finished iteration: 72 Time taken:1.0707623958587646\n",
      "Finished iteration: 73 Time taken:1.104785680770874\n",
      "Finished iteration: 74 Time taken:1.144813060760498\n",
      "Finished iteration: 75 Time taken:1.0622529983520508\n",
      "Finished iteration: 76 Time taken:1.0897736549377441\n",
      "Finished iteration: 77 Time taken:1.0282313823699951\n",
      "Finished iteration: 78 Time taken:1.0717613697052002\n",
      "Finished iteration: 79 Time taken:1.0459349155426025\n",
      "Finished iteration: 80 Time taken:1.0852715969085693\n",
      "Finished iteration: 81 Time taken:1.0877728462219238\n",
      "Finished iteration: 82 Time taken:1.091275691986084\n",
      "Finished iteration: 83 Time taken:1.1107892990112305\n",
      "Finished iteration: 84 Time taken:1.081268310546875\n",
      "Finished iteration: 85 Time taken:1.0677580833435059\n",
      "Finished iteration: 86 Time taken:1.0602545738220215\n",
      "Finished iteration: 87 Time taken:1.0507454872131348\n",
      "Finished iteration: 88 Time taken:1.0897753238677979\n",
      "Finished iteration: 89 Time taken:1.0752639770507812\n",
      "Finished iteration: 90 Time taken:1.0627830028533936\n",
      "Finished iteration: 91 Time taken:1.1205193996429443\n",
      "Finished iteration: 92 Time taken:1.1217987537384033\n",
      "Finished iteration: 93 Time taken:1.0967788696289062\n",
      "Finished iteration: 94 Time taken:1.050745964050293\n",
      "Finished iteration: 95 Time taken:1.0742621421813965\n",
      "Finished iteration: 96 Time taken:1.0927777290344238\n",
      "Finished iteration: 97 Time taken:1.048243522644043\n",
      "Finished iteration: 98 Time taken:1.05975341796875\n",
      "Finished iteration: 99 Time taken:1.0482497215270996\n"
     ]
    }
   ],
   "source": [
    "btm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "btm.save_result()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "0px",
    "width": "250px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
